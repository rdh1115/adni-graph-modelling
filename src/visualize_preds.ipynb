{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:35:20.512504Z",
     "start_time": "2024-10-04T06:35:20.449994Z"
    }
   },
   "source": [
    "from iopath.common.file_io import g_pathmgr as pathmgr\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import model_finetune\n",
    "from gmae_st.data.get_dataset import get_dataset\n",
    "from gmae_st.utils import misc\n",
    "from gmae_st.data.utils import DX_DICT\n",
    "from data.utils import collator"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T06:35:22.171845Z",
     "start_time": "2024-10-04T06:35:22.111577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_vis_dataset(\n",
    "        dataset_type,\n",
    "        dataset_name,\n",
    "        dataset_dir,\n",
    "        graph_token,\n",
    "        n_hist,\n",
    "        n_pred,\n",
    "        norm\n",
    "):\n",
    "    dataset_dict = get_dataset(\n",
    "        dataset_type=dataset_type,\n",
    "        dataset_name=dataset_name,\n",
    "        data_dir=dataset_dir,\n",
    "        n_hist=n_hist,\n",
    "        n_pred=n_pred,\n",
    "        task='pred',\n",
    "        graph_token=graph_token,\n",
    "        mode='test',\n",
    "        norm=norm\n",
    "    )\n",
    "    dataset_train = dataset_dict['train_dataset']\n",
    "    dataset_test = dataset_dict['test_dataset']\n",
    "    scaler = dataset_train.scaler\n",
    "    sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "    data_sample = dataset_train[0]\n",
    "    node_feature_dim = data_sample['x'].shape[-1]\n",
    "    num_nodes = data_sample['adj'].shape[0]\n",
    "    num_edges = len(data_sample['edge_attr'])\n",
    "\n",
    "    # account for data.utils.collator changes\n",
    "    num_spatial = torch.max(data_sample['spatial_pos']).item() + 1\n",
    "    num_in_degree = torch.max(data_sample['in_degree']).item() + 1\n",
    "    num_out_degree = torch.max(data_sample['out_degree']).item() + 1\n",
    "    graph_info = {\n",
    "        'node_feature_dim': node_feature_dim,\n",
    "        'num_nodes': num_nodes,\n",
    "        'num_edges': num_edges,\n",
    "        'num_spatial': num_spatial,\n",
    "        'num_in_degree': num_in_degree,\n",
    "        'num_out_degree': num_out_degree\n",
    "    }\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test,\n",
    "        sampler=sampler_test,\n",
    "        batch_size=1,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=partial(\n",
    "            collator,\n",
    "            max_node=num_nodes,\n",
    "            spatial_pos_max=num_spatial,\n",
    "            graph_token=graph_token,\n",
    "            scaler=scaler,\n",
    "        ),\n",
    "    )\n",
    "    return data_loader_test, graph_info\n",
    "\n",
    "\n",
    "def load_model(model_fp, model):\n",
    "    with pathmgr.open(model_fp, 'rb') as f:\n",
    "        checkpoint = torch.load(f, map_location='cpu')\n",
    "\n",
    "    if \"model\" in checkpoint.keys():\n",
    "        checkpoint_model = checkpoint[\"model\"]\n",
    "    else:\n",
    "        checkpoint_model = checkpoint[\"model_state\"]\n",
    "\n",
    "    msg = model.load_state_dict(\n",
    "        checkpoint_model,\n",
    "        strict=False\n",
    "    )\n",
    "    print(msg)\n",
    "    return model"
   ],
   "id": "6148b7c25a037b27",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T06:35:23.009096Z",
     "start_time": "2024-10-04T06:35:22.983220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_node_with_most_variance(dataloader):\n",
    "    max_variance = 0\n",
    "    node_with_most_variance = None\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        # data shape: [batch_size, time_steps, nodes, features]\n",
    "\n",
    "        # Compute variance across time steps and features for each node\n",
    "        # Variance is computed along the time steps and feature dimensions (dim=1 and dim=3)\n",
    "        # Resulting variance shape will be [batch_size, nodes]\n",
    "        variances = torch.var(data, dim=(1, 3))  # Variance over time steps and features\n",
    "\n",
    "        # Find the maximum variance and corresponding node index for each batch\n",
    "        max_batch_variance, max_batch_idx = torch.max(variances, dim=1)  # max over nodes\n",
    "\n",
    "        # Update the global maximum if the current batch has a higher variance node\n",
    "        batch_max_variance, node_idx = torch.max(max_batch_variance, dim=0)  # max over batches\n",
    "        if batch_max_variance > max_variance:\n",
    "            max_variance = batch_max_variance\n",
    "            node_with_most_variance = data[node_idx]\n",
    "\n",
    "    return node_with_most_variance, max_variance"
   ],
   "id": "e025c8aa7b6fe5ce",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T20:18:12.129467Z",
     "start_time": "2024-10-04T20:18:11.976439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_preds(\n",
    "        model,\n",
    "        args,\n",
    "        data_loader,\n",
    "):\n",
    "    header = \"Test:\"\n",
    "    device = torch.device('cpu')\n",
    "    # switch to evaluation atlas\n",
    "    model.eval()\n",
    "    task = 'pred'\n",
    "    model_pred = dict()\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        batch = misc.prepare_batch(batch, device=device)\n",
    "        scaler = None if 'scaler' not in batch else batch['scaler']\n",
    "\n",
    "        samples, targets = batch['x'], batch['y']\n",
    "        target_shape = targets.shape\n",
    "        # targets = scaler.inverse_transform(targets) if scaler else targets\n",
    "        if task == 'pred':\n",
    "            N, P, V, D = target_shape\n",
    "            if D == 2:\n",
    "                targets = targets[..., [0]]\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            preds = model(batch)\n",
    "            if scaler:\n",
    "                outputs = scaler.inverse_transform(preds)\n",
    "            else:\n",
    "                outputs = preds\n",
    "\n",
    "        ouptuts, targets = outputs.view(N * P, V), targets.view(N * P, V)\n",
    "        for node in range(batch['x'].shape[2]):\n",
    "            node_output = outputs[:, node]\n",
    "            node_targets = targets[:, node]\n",
    "            if not node in model_pred:\n",
    "                model_pred[node] = dict()\n",
    "                model_pred[node]['pred'] = node_output\n",
    "                model_pred[node]['target'] = node_targets\n",
    "            else:\n",
    "                model_pred[node]['pred'] = torch.cat(\n",
    "                    (model_pred[node]['pred'], node_output),\n",
    "                    dim=0\n",
    "                )\n",
    "                model_pred[node]['target'] = torch.cat(\n",
    "                    (model_pred[node]['target'], node_targets),\n",
    "                    dim=0\n",
    "                )\n",
    "        if i == 2:\n",
    "            break\n",
    "    return model_pred\n",
    "\n",
    "\n",
    "def visualize_pred(\n",
    "        pred,\n",
    "        dataset_args,\n",
    "        dataset_loader,\n",
    "        time_step_idx,\n",
    "        node_idx_list,\n",
    "):\n",
    "    # Set up the figure with one subplot for each node in node_idx_list\n",
    "    fig, ax = plt.subplots(len(node_idx_list), 1, figsize=(20, 12), sharex=True)\n",
    "    color = [\"#00798c\", \"#d1495b\"]\n",
    "\n",
    "    # Loop over each node in node_idx_list\n",
    "    for i, node_idx in enumerate(node_idx_list):\n",
    "        # Get predictions and targets for the specific node and time_step_idx\n",
    "        node_preds = pred[node_idx]['pred'][time_step_idx].detach().cpu().numpy()  # Index with time_step_idx\n",
    "        node_targets = pred[node_idx]['target'][time_step_idx].detach().cpu().numpy()\n",
    "\n",
    "        # Time steps for x-axis (assumed dataset_args or similar provides information about time steps)\n",
    "        time_steps = list(range(node_preds.shape[0]))\n",
    "\n",
    "        # Plot both predictions and targets on the same subplot\n",
    "        ax[i].plot(time_steps, node_preds, color=color[0], label='Predictions')\n",
    "        ax[i].plot(time_steps, node_targets, color=color[1], label='Ground Truth')\n",
    "        ax[i].set_title(f'Predictions vs Ground Truth for Node {node_idx} at Time Step {time_step_idx}', fontsize=16)\n",
    "        ax[i].set_ylim(min(node_preds.min(), node_targets.min()) - 1, max(node_preds.max(), node_targets.max()) + 1)\n",
    "        ax[i].legend(loc='upper left')\n",
    "\n",
    "        # Remove top and right spines\n",
    "        for s in ['top', 'right']:\n",
    "            ax[i].spines[s].set_visible(False)\n",
    "\n",
    "    # Shared x-label\n",
    "    plt.xlabel('Time Steps', fontsize=14)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ],
   "id": "cb34bd267e1ae360",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T20:18:13.717360Z",
     "start_time": "2024-10-04T20:18:13.702715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vis_pipeline(\n",
    "        model_fp,\n",
    "        dataset_args=None,\n",
    "        time_step_idx=[0, 1, 2, 3, 4, 5],\n",
    "        node_idx=[0],\n",
    "        seed=0,\n",
    "):\n",
    "    if not dataset_args:\n",
    "        n_hist, n_pred = 12, 12\n",
    "        norm = True\n",
    "        graph_token = False\n",
    "        dataset_type = 'traffic'\n",
    "        dataset_name = 'metr-la'\n",
    "        dataset_dir = ''\n",
    "        dataset_args = {\n",
    "            'dataset_type': dataset_type,\n",
    "            'dataset_dir': dataset_dir,\n",
    "            'dataset_name': dataset_name,\n",
    "            'n_hist': n_hist,\n",
    "            'n_pred': n_pred,\n",
    "            'norm': norm,\n",
    "            'graph_token': graph_token,\n",
    "        }\n",
    "    loader, graph_info = get_vis_dataset(\n",
    "        **dataset_args\n",
    "    )\n",
    "    dataset_args.update(graph_info)\n",
    "    print(dataset_args)\n",
    "    model = model_finetune.graph_causal_pred_mini(\n",
    "        sep_pos_embed=False,\n",
    "        cls_token=False if dataset_args['graph_token'] else True,\n",
    "        end_channel=64,\n",
    "        **dataset_args\n",
    "    )\n",
    "    model = load_model(\n",
    "        model_fp=model_fp,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    preds = get_preds(model, dataset_args, loader)\n",
    "    visualize_pred(preds, dataset_args, loader, time_step_idx, node_idx)\n",
    "    return preds"
   ],
   "id": "636c44473e8117d4",
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "preds = vis_pipeline(\n",
    "    '/Users/markbai/Documents/gmae_st/metr-la_causal-pred-mini_checkpoint-00099.pth'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-04T20:18:14.397198Z"
    }
   },
   "id": "468db1cb16d5a8a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using normalization with mean: 54.40592829587617, std: 19.493739270573087\n",
      " > metr-la loaded!\n",
      "{'train_dataset': GraphTemporalDataset(23974), 'valid_dataset': GraphTemporalDataset(3425), 'test_dataset': GraphTemporalDataset(6850)}\n",
      " > dataset info ends\n",
      "{'dataset_type': 'traffic', 'dataset_dir': '', 'dataset_name': 'metr-la', 'n_hist': 12, 'n_pred': 12, 'norm': True, 'graph_token': False, 'node_feature_dim': 2, 'num_nodes': 207, 'num_edges': 22167, 'num_spatial': 12, 'num_in_degree': 155, 'num_out_degree': 155}\n",
      "model initialized\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(80290) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(80294) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(80297) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "preds[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T18:29:03.493243Z",
     "start_time": "2024-10-04T18:29:02.787887Z"
    }
   },
   "id": "33b02faf668d7db8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpreds\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'preds' is not defined"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "ba4def287cd56f5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
